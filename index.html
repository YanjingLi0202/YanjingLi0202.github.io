<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	<meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <script type="text/javascript" src="./res/shownews.js"></script>
    <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a { 
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    .hp-photo{ width:191px; height:191px; border-radius:191px; -webkit-border-radius:191px; -moz-border-radius:191px; }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 24px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 700
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }

    #hidden_news {
        display: none;
    }

    #hide_news_botton {
        cursor: pointer;
    }

    #hidden_events {
        display: none;
    }

    #hide_events_botton {
        cursor: pointer;
    }
    </style>

    <title>Yanjing Li</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/jpg" href="https://YanjingLi0202.github.io/Imgs/buaa_icon.jpg">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td>

    <!--SECTION 1 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
              <td width="75%" valign="middle">
                <p align="center"><name>Yanjing Li</name></p>
                <p align="justify">I am a PhD candidate (2020.09-) at the School of Electronics and Information Engineering, 
                    <a href="https://www.buaa.edu.cn/">Beihang University</a>,
                    supervised by Prof. <a href="">Xianbin Cao</a>
                    and Prof. <a href="">Baochang Zhang</a>. 
                    I obtained my BSc degree in Shen Yuan Honors College (Electronics and Information Engineering) from <a href="https://www.buaa.edu.cn/">Beihang University</a> (2016.09-2020.06).
                    <br><br>
                    Now I am an research intern (2022.11-) of <a href="">Shanghai AI Lab</a>, and I was interned at <a href="">Fundamental Vision Group of Sensetime</a> in 2021. 
                    <br><br>
                    <strong>Email:</strong> yanjingli@buaa.edu.cn
                <br>
                
                </p><p align="center">
                    <a href="https://scholar.google.com/citations?user=2rE-GM8AAAAJ">Google Scholar</a> / 
                    <a href="https://github.com/YanjingLi0202/"> Github </a> / 
                </p>
                
              </td></tr>
            </tbody>
          </table>

    <!--SECTION 2 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
       <tbody><tr>
          <td>
          <heading>Research</heading>
            <p align="justify">My area of interest lies in the techniques of <strong><i>network binarization and quantization</i></strong>, along with knowledge distillation. 
            My research objective is to facilitate the deployment of advanced neural network models on hardware with limited resources. 
            This involves compressing various neural architectures and ensuring their adaptable deployment on diverse hardware platforms.
		   </td></tr>
       </tbody>
    </table>


    <!--SECTION 3 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
          <td>
          <heading>Selected Publications<a name="publications"></a>
        </heading>
        <p>
        Full list can be found on <a href="https://scholar.google.com/citations?user=2rE-GM8AAAAJ">Google Scholar</a>.
        </p>
        </td></tbody>
    </table>
    
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        
		<tbody>
			
	<tr><td width="20%"><img src="./imgs/q-detr.png" alt="PontTuset" width="180" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="#">
                <papertitle>Q-DETR: An Efficient Low-Bit Quantized Detection Transformer</papertitle></a>
		[<a href="#" target="_blank">pdf coming</a>]
                <br>Sheng Xu<sup>*</sup>, <strong>Yanjing Li</strong><sup>*</sup>, Mingbao Lin, Peng Gao, Guodong Guo, Jinhu Lu, Baochang Zhang<sup>âœ‰</sup>
                <br>
                <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2023
                <br>
                <a href="#">arXiv</a> / 
                <a href="#"><font color="red">Code</font></a> 
                <iframe src="https://ghbtns.com/github-btn.html?user=#&repo=#&type=star&count=true&size=small"
                    frameborder="0" scrolling="0" width="100px" height="20px"></iframe>
                </p><p></p>
                <p align="justify" style="font-size:13px">In this paper, we propose Q-DETR.</p>
                <p></p>
		<p align="justify" style="font-size:13px">(<sup>*</sup> Equal Contribution)</p>
            </td>
        </tr>
	
	<tr><td width="20%"><img src="./imgs/rebnn.png" alt="PontTuset" width="180" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="#">
                <papertitle>Resilient Binary Neural Network</papertitle></a>
		[<a href="#" target="_blank">pdf coming</a>]
                <br>Sheng Xu<sup>*</sup>, <strong>Yanjing Li</strong><sup>*</sup>, Teli Ma<sup>*</sup>, Mingbao Lin, Hao Dong, Baochang Zhang, Peng Gao, Jinhu Lu
     		<br>
                <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023
		<em><font color="red">Oral presentation</font></em>
                <br>
                <a href="https://arxiv.org/abs/2302.00956">arXiv</a> / 
                <a href="https://github.com/SteveTsui/ReBNN"><font color="red">Code</font></a> 
                <iframe src="https://ghbtns.com/github-btn.html?user=SteveTsui&repo=ReBNN&type=star&count=true&size=small"
                    frameborder="0" scrolling="0" width="100px" height="20px"></iframe>
                </p><p></p>
                <p align="justify" style="font-size:13px">In this paper, we propose Q-DETR.</p>
		<p></p>
		<p align="justify" style="font-size:13px">(<sup>*</sup> Equal Contribution)</p>
            </td>
        </tr>
	
	<tr><td width="20%"><img src="./imgs/q-vit.png" alt="PontTuset" width="180" style="border-style: none"></td>
            <td width="80%" valign="top">
	            <p><a href="https://openreview.net/pdf?id=fU-m9kQe0ke">
                <papertitle>Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer</papertitle></a>
		[<a href="https://openreview.net/pdf?id=fU-m9kQe0ke">PDF</a>]
                <br><strong>Yanjing Li</strong><sup>*</sup>, Sheng Xu<sup>*</sup>, Baochang Zhang, Xianbin Cao, Peng Gao, Guodong Guo
     		<br>
                <em> Conference on Neural Information Processing Systems (NeurIPS)</em>, 2022
                <br>
                <a href="https://arxiv.org/pdf/2210.06707.pdf">arXiv</a> / 
                <a href="https://github.com/YanjingLi0202/Q-ViT"><font color="red">Code</font></a> 
                <iframe src="https://ghbtns.com/github-btn.html?user=YanjingLi0202&repo=Q+ViT&type=star&count=true&size=small"
                    frameborder="0" scrolling="0" width="100px" height="20px"></iframe>
                </p><p></p>
                <p align="justify" style="font-size:13px">In this paper, we propose Q-ViT.</p>
		<p></p>
		<p align="justify" style="font-size:13px">(<sup>*</sup> Equal Contribution)</p>
            </td>
        </tr>


        </tbody>
    </table>


    <!--SECTION 4 -->
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody><tr>
           <td><heading>Academic Services</heading>
            <p> <strong>Program Committee</strong> of Conferences: CVPR 2022/2023, ECCV 2022, etc.</p>
           </td>
           </tr></tbody>
   </table>

